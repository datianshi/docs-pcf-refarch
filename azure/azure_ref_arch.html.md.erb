---
title: Azure Reference Architecture
owner: Customer0
---

This guide presents a reference architecture for Pivotal Cloud Foundry (PCF) on Azure.


## <a id="overview"></a> Overview

Azure Virtual Data Center (VDC) uses a hub and spoke model for extending on-premises data centers. When installing PCF, you can use this model to place resources in resource groups. For example, a PCF installation contains the following:

* **Hub**: 
	* A central IT resource group included in Azure VDC setup. This is where you define firewall, access control, and security policies. 
* **Spokes**: 
  * A Network resource group for all network resource
  * PAS/PKS resource groups for all PAS/PKS resources

See the following architecture diagram, which illustrates this model: 

![alt_text](../images/PAS_Azure_with_AZs.png) 

[View a larger version of this diagram](https://raw.githubusercontent.com/pivotal-cf/docs-pcf-refarch/master/images/PAS_Azure_with_AZs.png).

 For more information about VDC, see the [Azure Virtual Datacenter e-book](https://azure.microsoft.com/en-us/resources/azure-virtual-datacenter/).

## <a id="networking"></a> Networking

### <a id="network-considerations"></a> General Considerations

* You must enable Virtual Network peering between hub and spoke resource groups. See [Virtual network peering](https://docs.microsoft.com/en-us/azure/virtual-network/virtual-network-peering-overview). 
* You can use Express routes or VPN Gateway to enable connectivity from an on-premises data center to Azure Hub resource groups. See [ExpressRoute Documentation](https://docs.microsoft.com/en-us/azure/expressroute/).  
* You can place network resources, such as DNS and NTP servers, either on-premises or on Azure cloud. 
* A separate subscription for central network resource group (Hub) and each workspace where each workload runs (spoke) is needed.
*   If you want Internet ingress, create the load balancers with elastic IPs
*   Use ExpressRoutes for dedicated connection from on-premises datacenter to VDC
*   Use Azure VPN Gateways for passing encrypted data into VDC via internet.  Use this option as backup, if Express Routes goes down.
*   Setup a central firewall in the Hub resource group to enhance and to do data infiltration - data coming in and also data exfiltration using network virtual appliance.

### <a id="lb-types"></a>  Load Balancing

Use Standard Azure Load Balancers (ALBs). 

Consider the following:

* The ALBs must be configured for PAS Gorouters. 
* The PAS system and applications domains should resolve to this ALB and have either a private or a public IP address assigned to it. 
* When applicable, TCP Routers and SSH Proxies also require load balancers.

### <a id="networks"></a> Networks

PCF requires the networks defined in the base reference architectures for PAS and PKS. See the _Networks_ sections in [Platform Architecture and Planning](../index.html). 

### <a id="dns"></a> DNS

You can use Azure DNS zones for PCF domains. Azure DNS supports DNS delegation, which allows sub-level domains to be hosted within Azure. Pivotal recommends that you use a sub-zone for your PCF deployment. For example, if your company’s domain is `example.com`, your PCF zone in Azure DNS would be `pcf.example.com`.

Azure DNS does not support recursion. To properly configure Azure DNS, do the following:

1. Create a `NS `record with your registrar that points to the four name servers supplied by your Azure DNS Zone configuration. 
1. Create the required wildcard `A` records for the PCF app and system domains, as well as any other records desired for your PCF deployments.

You do not need to make any configuration changes in PCF to support Azure DNS.

### <a id="pas-single-azure-resource"></a> PAS on a Single Azure Resource Group

If shared network resources do not exist in an Azure subscription, you can use a single resource group to deploy PCF and define network constructs.

## <a id="ha-considerations"></a>  High Availability

<p class="note"><strong>Note</strong>: As of PCF v2.5.3, PCF on Azure supports both availability zones (AZ) and Availability Sets.</p>

Pivotal recommends that you use AZs instead of Availability Sets in all Azure regions where they are available. AZs solve the cluster pinning issue described in the sections below and allow greater control when defining the high availability configuration when using Azure multiple services. 

See the following for additional guidance depending on your use case:

* **New foundations**: 
	* If you do not have hard requirements, select AZ enabled regions. Examples of hard requirements include existing ExpressRoute connections from non-AZ enabled regions to customer data centers and app-specific latency requirements. 
* **Existing foundations in AZ enabled regions**: 
	* Migrate to a new PCF v2.5.3+ foundation so that you can use AZs. These existing foundations, especially those using older families of VMs such as  `DS_v2`, risk running out of capacity as they scale. 
* **Existing foundations not in AZ enabled regions**:
	* Evaluate your requirements to determine the cost/benefit of migrating to an AZ enabled region.



For more information about availability modes in Azure, see [Manage the availability of Windows virtual machines in Azure](https://docs.microsoft.com/en-us/azure/virtual-machines/virtual-machines-windows-manage-availability) in the Microsoft Azure documentation. 

### <a id="AZ"></a> Availability Zones

AZs are an Azure primitive that supports high availability within a region. AZs are physically separate data centers in the same region, each comprised of separate power, cooling, and network. 

The following diagram illustrates PAS deployed on Azure using AZs:

![alt_text](../images/PAS_Azure.png) 

[View a larger version of this diagram](https://raw.githubusercontent.com/pivotal-cf/docs-pcf-refarch/master/images/PAS_Azure.png).

AZs have the following advantages:

* VMs and other zonal services deployed to independent zones provide greater physical separation than fault domains and avoid the cluster pinning problem of availability sets. 
* Zonal services are effectively in separate update domains as updates are rolled out to one zone at a time. 
* AZs are visible and configurable. Two zonal services placed in the same logical zone are also placed in the same physical zone. This allows services of different types to take advantage of the highly available qualities a zone provides.


### <a id="AS"></a> Availability Sets


Availability Sets were the first Azure primitive to support high availability   within a region. They have the following properties:

* They are a logical concept that ensures multiple VMs in the same set are spread evenly across 3 Fault Domains and either 5 or 20 Update Domains. 
* VMs on independent Fault Domains are guaranteed not to share power supply or networking and will therefore maintain availability of a subset of VMs in the set when a hardware issue occurs. 
* VMs in independent Update Domains, when updates are rolled out to a Cluster, will not be updated at the same time, ensuring downtime incurred by an update does not affect the availability of the set. 

#### <a id="cluster-pinning"></a> Cluster Pinning Issues

Azure implements availability sets in a single cluster, which is a group of hardware for Azure Compute.

In PCF on Azure, VMs for a particular job are pinned to the cluster where the first VM spins up. This is because BOSH places VMs for jobs within the same Availability Sets. 

Cluster pinning causes the following:

* Issues migrating jobs from one family of VMs to another, backed by different hardware, such as `DS_v2` and `DS_v3`
* Issues scaling up if there is no capacity on the given cluster


## <a id="storage-considerations"></a> Storage

For storage, Pivotal recommends the following:

* For the storage account type, use the premium performance tier. 
* Configure storage accounts for Zone Redundant Storage (ZRS) in AZ-enabled Regions. 
	<p class="note"><strong>Note</strong>: In Non-Availability-zone-enabled Regions, Locally Redundant Storage (LRS) is sufficient.</p> 
* Configure VMs to use managed disks instead of manually-managed VHDs on storage accounts. Managed disks are an Azure feature that handles the correct distribution of VHDs over storage accounts to maintain high IOPS as well as high availability for the VMs.
* Use 5 storage accounts. PCF on Azure requires 5 storage accounts: 1 BOSH, 1 Ops Manager, and 3 PAS storage accounts. Each account comes with a set amount of disk. Azure Storage Accounts have an IOPs limit of approximately 20k per account, which generally corresponds to a BOSH JOB/VM limit of approximately 20 VMs each.


## <a id="sql-server"></a> SQL Server

The Internal MySQL database provided by PAS is sufficient for production use.


## <a id="blobstore-storage-accts"></a>  Blobstore Storage Account

Pivotal recommends using Azure Blob Storage as the external file storage option for PCF. This provides unlimited scaling and redundancy for high-availability deployments of PCF. Azure Blob Storage provides fully-redundant hot, cold, or archival storage in either local, regional, or global offerings. 

Ops Manager requires a bucket for the BOSH blobstore. 

PAS requires the following buckets:

*   Buildpacks
*   Droplets
*   Packages
*   Resources

These buckets require an associated role for read/write access.

## <a id="identity-management"></a> Identity Management

Pivotal recommends using unique managed identities to deploy Ops Manager, BOSH Director, Microsoft Azure Service Broker, and any other tiles that require independent credentials. Ensure that each managed identity is scoped to the least privilege necessary to operate.

Azure uses managed identities to handle service authorization. See [What is managed identities for Azure resources?](https://docs.microsoft.com/en-us/azure/active-directory/managed-identities-azure-resources/overview). 
